{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Notebook\n",
    "\n",
    "This notebook will crawl to the www.fbi.gov website and will download all the crimes statistics of each city in the USA, between the years 2010 - 2019.\n",
    "\n",
    "The crawler will begin its crawling in the main page of the site and will crawl several page and will export all the relvent data to EXCEL files.\n",
    "This notebook consist all the functions that will crawl,export, merge and edit the desired files from the FBI website that we will use in this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "import time      # for testing use only\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import re\n",
    "from urllib import request #for download excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## opening soup object \n",
    "\n",
    "def load_soup_object(url):\n",
    "    respons = requests.get(url)\n",
    "    soup = BeautifulSoup(respons.content, \"html.parser\")\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download files  \n",
    "\n",
    "def download_file(file_url, name):\n",
    "    r = requests.get(file_url, allow_redirects=True)\n",
    "    name = str(name) + '.xls'\n",
    "    open(name, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for the crime statistics for years 2018 and 2019 to edit \n",
    "\n",
    "def file_edit(name): \n",
    "    direct = '/Users/barbenshabat/Downloads/Datascience/project/' + str(name) + '.xls'\n",
    "    df = pd.read_excel(direct)\n",
    "    df = pd.read_excel(name)\n",
    "    df.dropna(axis=0, thresh=8, inplace=True)\n",
    "    col_names = df.iloc[0]#col infirst row insted of the real place\n",
    "    x=df.iloc[:0]\n",
    "    for i in x: df.rename(columns={i:col_names[i]}, inplace=True)#swich unnamed in real names\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop([0], inplace=True)#hadle reset index\n",
    "    df.drop(['index'], axis=1,inplace=True)#hadle reset index\n",
    "    if ('State' in df.columns):\n",
    "         df.State.fillna(method='ffill', inplace=True)#filling states\n",
    "    df.to_excel(str(name)+'_eddited_'+'.xlsx', engine='xlsxwriter')#write to excel\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit table 8 crime statistics  \n",
    "\n",
    "def file_edit_macro_table_8():\n",
    "    table_8_files = []\n",
    "    for year in range(0,10):\n",
    "        table_8_files.append('Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_'+str((2010+year))+'_eddited_.xlsx')\n",
    "    table_8_files\n",
    "    \n",
    "    col = []\n",
    "    final_col_names = pd.read_excel(path+table_8_files[0]).columns\n",
    "\n",
    "    for i in range(0,10):\n",
    "        df = pd.read_excel(path+table_8_files[i])\n",
    "        df.dropna(axis=1, inplace=True, thresh=100)\n",
    "        if i in range (3,7):\n",
    "            values = {'Rape\\n(revised\\ndefinition)1' : 0, 'Rape\\n(legacy\\ndefinition)2' :0}\n",
    "            df.fillna(value=values, inplace=True)\n",
    "            sum_rape = df['Rape\\n(revised\\ndefinition)1']+df['Rape\\n(legacy\\ndefinition)2']\n",
    "            df.insert(6, 'Rape', sum_rape)\n",
    "            df.drop(['Rape\\n(revised\\ndefinition)1','Rape\\n(legacy\\ndefinition)2'] ,axis=1, inplace=True)\n",
    "        for j in range(0,len(final_col_names)): df.rename(columns={df.columns[j]:final_col_names[j]},inplace=True)\n",
    "        df.rename(columns={'Unnamed: 0':'Year'},inplace=True)\n",
    "        df['Year']=str(2010+i)\n",
    "        col.append(df.columns)\n",
    "        df.to_excel(table_8_files[i], engine='xlsxwriter')#write to excel\n",
    "    return ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging each crime statistics file \n",
    "\n",
    "def merge_Table_8():\n",
    "    file_edit_macro_table_8()\n",
    "    table_8_files = []\n",
    "    for year in range(0,10):\n",
    "        table_8_files.append('Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_'+str((2010+year))+'_eddited_.xlsx')\n",
    "    dfs_list = []\n",
    "    path ='/Users/barbenshabat/Downloads/Datascience/project/'\n",
    "\n",
    "    for f in range(0,10):\n",
    "        df = pd.read_excel(path+table_8_files[f]) # read each file in the folder \n",
    "        dfs_list.append(df) # inserting each df to a list\n",
    "\n",
    "    main_df = pd.concat(dfs_list,axis=0) # concanicating each df into main df \n",
    "    main_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    main_df.to_excel('merge_table_8.xlsx',engine='xlsxwriter')\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawling \n",
    "\n",
    "This function begins the Crawling to the FBI site.\n",
    "After the crawling is finished  data sets will be downloaded.\n",
    "* Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City 2010 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawling and downloading filies from the FBI site #\n",
    "#####################################################\n",
    "#####################################################\n",
    "\n",
    "def Crawling_and_downloadin_table_8_10():   \n",
    "    #----------------------------------------->Crawling\n",
    "\n",
    "    FBI_url = f\"https://www.fbi.gov\" #FBI URL\n",
    "    respons = requests.get(FBI_url)\n",
    "    soup = BeautifulSoup(respons.content, \"html.parser\")\n",
    "\n",
    "    #----------------------------------------->FBI home page -> Crime Statistics\n",
    "\n",
    "    mtag=soup.find_all(\"div\",attrs={\"class\":\"footer-nav-group\"})\n",
    "    linksToPages=[t['href'] for t in mtag[len(mtag)-1].find_all(\"a\")]\n",
    "    #linksToPages[2]#link to crime statistics\n",
    "    soup=load_soup_object(linksToPages[2])\n",
    "\n",
    "    #----------------------------------------->Crime Statistics -> UCR Publications page\n",
    "\n",
    "    mtag=soup.find_all(\"div\",attrs={\"class\":\"movable removable mosaic-tile mosaic-plone.app.standardtiles.rawhtml-tile mosaic-tile-background\"})[0]\n",
    "    soup=load_soup_object(mtag(\"p\")[1].a[\"href\"])\n",
    "\n",
    "    #----------------------------------------->UCR Publications page -> Eace year in Crime in the United States \n",
    "\n",
    "    mtag=soup.find_all(\"li\",attrs={\"visualClear\"})\n",
    "\n",
    "    years19_05 = []\n",
    "    how_mani_crimes19_05=[]\n",
    "    excel_links19_05=[]\n",
    "    murdered_strang_know=[]\n",
    "    excel_links_2_19_05=[]\n",
    "\n",
    "    #Fetting links to all yers pages\n",
    "    for year in range(0,10):                   \n",
    "        years19_05.append(mtag[year].a[\"href\"])\n",
    "\n",
    "    #----------------------------------------->Eace year in Crime in the United States -> Excels pages\n",
    "\n",
    "    #For each yea getting links to excel page from each year\n",
    "    for x in range(0,10):      \n",
    "        soup = load_soup_object(years19_05[x])\n",
    "        mtag=soup.find_all(\"div\",attrs={\"qfind_item\"})\n",
    "        how_mani_crimes19_05.append(mtag[0].a[\"href\"])#How many crimes came to the attention of law enforcement in my city in 2019? \n",
    "        murdered_strang_know.append(mtag[2].a[\"href\"])#Are more people murdered by a stranger or by someone they know? \n",
    "\n",
    "\n",
    "    #------------------------------------------>Download file Excel files\n",
    "\n",
    "    #Menually download only for 2018, 2017 need to be download!\n",
    "    file_edit('Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2018')\n",
    "    file_edit('Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2017')\n",
    "\n",
    "    for y in range(0,10):\n",
    "        soup=load_soup_object(how_mani_crimes19_05[y])\n",
    "        x=soup.find_all(lambda tag: tag.name == 'li' and tag.get('class') == ['last'])\n",
    "        for i in range(0, len(x)):\n",
    "            if x[i].a.string == 'Download Excel':\n",
    "                excel_links19_05.append(x[i].a[\"href\"])\n",
    "                download_file(x[i].a[\"href\"], 'Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_'+str(2019-y))\n",
    "                df=file_edit('Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_'+str(2019-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Editing the crime statistics data sets \n",
    "\n",
    "def file_edit_table_78(file):\n",
    "    df = pd.read_excel(file)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.dropna(axis=0, thresh=2, inplace=True)\n",
    "    col_names = df.iloc[0]#col infirst row insted of the real place\n",
    "    x=df.iloc[:0]\n",
    "    for i in x: df.rename(columns={i:col_names[i]}, inplace=True)#swich unnamed in real names\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop([0], inplace=True)#hadle reset index\n",
    "    df.rename(columns={'index':'Year'},inplace=True)\n",
    "    df['Year']=2010+int(file[file.find('201')+3])\n",
    "    if ('State' in df.columns):\n",
    "        df.State.fillna(method='ffill', inplace=True)#filling states\n",
    "    df.dropna(axis=1,thresh=4, inplace=True)\n",
    "    values = {df.columns[4]:0, df.columns[5]:0, df.columns[6]:0}\n",
    "    df.fillna(value=values, inplace=True)\n",
    "    total_officers = df[df.columns[4]]+df[df.columns[5]]+df[df.columns[6]]\n",
    "    df.insert(7, 'Total_Police force', total_officers)\n",
    "    df.to_excel(file+'_eddited'+'.xlsx', engine='xlsxwriter')#write to excel\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming the columns function \n",
    "\n",
    "def rename_coln_names(df, col_names):\n",
    "    for j in range(0,len(col_names)): df.rename(columns={df.columns[j]:col_names[j]},inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge law enforcement data sets to the main crime data set\n",
    "\n",
    "def merge_table8_and_table78():\n",
    "    name78='Table_78_Full-time_Law_Enforcement_Employees_by_State_by_City_201' #.xls_eddited.xlsx\n",
    "    path78='/Users/barbenshabat/Downloads/Datascience/project/Table_78/'\n",
    "    name_main8='merge_table_8.xlsx'\n",
    "    path_main8='/Users/barbenshabat/Downloads/Datascience/project/'\n",
    "    \n",
    "    df_main8= pd.read_excel(path_main8+name_main8) #LEFT\n",
    "    \n",
    "    for y in np.arange(1): \n",
    "        df78=pd.read_excel(path78+name78+str(y)+'.xls_eddited.xlsx') #RIGHT\n",
    "        result = pd.merge(df78, df_main8, how=\"outer\")#on=[\"Year\", \"State\", \"City\"]\n",
    "    return result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling the crawling and merging functions###\n",
    "################################################\n",
    "\n",
    "Crawling_and_downloadin_table_8_10()\n",
    "main_df=merge_Table_8()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
